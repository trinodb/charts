image:
  repository: trinodb/trino
  tag: 363
  pullPolicy: IfNotPresent
  securityContext:
    runAsUser: 1000
    runAsGroup: 1000

env: []
# Both worker & coordinator can use environment variables to expose information about itself to Containers running in the Pod

ingress:
  enabled: false
  annotations: {}
  host: ""
  tls:
    secretName: ""

server:
  workers: 3
  node:
    environment: production
    dataDir: /data/trino
    pluginDir: /usr/lib/trino/plugin
  log:
    trino:
      level: INFO
  config:
    path: /etc/trino
    http:
      port: 8080
    processForwarded: false
    # Trino supports multiple authentication types: PASSWORD, CERTIFICATE, OAUTH2, JWT, KERBEROS
    # For more info: https://trino.io/docs/current/security/authentication-types.html
    # authenticationType: "PASSWORD"
    httpsServer:
      enabled: false
      port: 8443
      keystore:
        path: "/usr/local/certs/clustercoord.pem"
        # JKS keystores always require a password, while PEM format certificates can optionally require a password
        key: ""
    query:
      maxMemory: "3GB"
      maxMemoryPerNode: "1GB"
      maxTotalMemory: "6GB"
      maxTotalMemoryPerNode: "2GB"
    prestoCompatibleHeader: false
  jvm:
    maxHeapSize: "7G"
    gcMethod:
      type: "UseG1GC"
      g1:
        heapRegionSize: "32M"
  autoscaler:
    enabled: false
    maxReplicas: 5
    targetCPUUtilizationPercentage: 50

initContainers: {}
  # coordinator:
  #   - name: init-coordinator
  #     image: busybox:1.28
  #     imagePullPolicy: IfNotPresent
  #     command: ['sh', '-c', "until nslookup myservice.$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace).svc.cluster.local; do echo waiting for myservice; sleep 2; done"]
  # worker:
  #   - name: init-worker
  #     image: busybox:1.28
  #     command: ['sh', '-c', 'echo The worker is running! && sleep 3600']

auth: {}
  # Set username and password
  # https://trino.io/docs/current/security/password-file.html#file-format
  # passwordAuth: "username:encrypted-password-with-htpasswd"

accessControl: {}
  # # Supported types: pvc or configmap
  # type: pvc
  # refreshPeriod: 1s
  # # Rules file is mounted to /etc/trino/access-control
  # configFile: "/access-control/rules.json"
  # # If you use pvc as the type, you have to specify the pvcName field:
  # pvcName:
  # # If you use pvc as the type, you can specify the name of the volume with the pvcVolumeName:
  # pvcVolumeName:
  # # If you use configmap as the type, you have to specify the rules field:
  # rules:
  #   rules.json: |-
  #     {
  #       "catalogs": [
  #         {
  #           "user": "admin",
  #           "catalog": "(mysql|system)",
  #           "allow": "all"
  #         },
  #         {
  #           "group": "finance|human_resources",
  #           "catalog": "postgres",
  #           "allow": true
  #         },
  #         {
  #           "catalog": "hive",
  #           "allow": "all"
  #         },
  #         {
  #           "user": "alice",
  #           "catalog": "postgresql",
  #           "allow": "read-only"
  #         },
  #         {
  #           "catalog": "system",
  #           "allow": "none"
  #         }
  #       ],
  #       "schemas": [
  #         {
  #           "user": "admin",
  #           "schema": ".*",
  #           "owner": true
  #         },
  #         {
  #           "user": "guest",
  #           "owner": false
  #         },
  #         {
  #           "catalog": "default",
  #           "schema": "default",
  #           "owner": true
  #         }
  #       ]
  #     }

# If you want to provide your own secrets resource, you can use this field:
# connectorsSecret:

connectors: {}
  # Connectors configuration usually contains sensitive data (like passwords, usernames, ...)
  # so data is stored in a secret
  # mysql.properties: |-
  #   connector.name=mysql
  #   connection-url=jdbc:mysql://mysqlserver:3306
  #   connection-user=mysqluser
  #   connection-password=mysqlpassword
  # elk.properties: |-
  #   connector.name=elasticsearch
  #   elasticsearch.host=elasticsearchserver
  #   elasticsearch.port=9200
  #   elasticsearch.default-schema-name=default
  #   elasticsearch.security=PASSWORD
  #   elasticsearch.auth.user=elastiuser
  #   elasticsearch.auth.password=elasticpassword
  #   elasticsearch.tls.enabled=true

schemas: {}
  # Custom schemas that will be mounted in /etc/trino/schemas
  # testschema.json: |-
  #   {
  #     "tableName": "testtable",
  #     "schemaName": "testschema",
  #     "topicName": "testtopic",
  #     "key": {
  #         "dataFormat": "json",
  #         "fields": [
  #             {
  #                 "name": "_key",
  #                 "dataFormat": "VARCHAR",
  #                 "type": "VARCHAR",
  #                 "hidden": "false"
  #             }
  #         ]
  #     },
  #     "message": {
  #         "dataFormat": "json",
  #         "fields": [
  #             {
  #                 "name": "id",
  #                 "mapping": "id",
  #                 "type": "BIGINT"
  #             },
  #             {
  #                 "name": "test_field",
  #                 "mapping": "test_field",
  #                 "type": "VARCHAR"
  #             }
  #         ]
  #     }
  #   }

service:
  type: ClusterIP

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

secretMounts: []
  # - name: ssl-cert
  #   secretName: ssl-cert
  #   path: /usr/local/certs/
